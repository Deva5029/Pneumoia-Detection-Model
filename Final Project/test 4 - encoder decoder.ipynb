{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536aa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from skimage import exposure\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693e42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get training data\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    labels = ['PNEUMONIA', 'NORMAL']\n",
    "    img_size = 150\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9501f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/h9z_23v10pj2hclcsszt6v2c0000gn/T/ipykernel_79119/2024085280.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data)\n"
     ]
    }
   ],
   "source": [
    "# Load training, testing, and validation data\n",
    "train = get_training_data('/Users/deva/Desktop/DEVA/CSUN/Sem_3/Research/chest_xray/train')\n",
    "test = get_training_data('/Users/deva/Desktop/DEVA/CSUN/Sem_3/Research/chest_xray/test')\n",
    "val = get_training_data('/Users/deva/Desktop/DEVA/CSUN/Sem_3/Research/chest_xray/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663c71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "x_train, y_train = zip(*train)\n",
    "x_test, y_test = zip(*test)\n",
    "x_val, y_val = zip(*val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f502f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "x_val = np.array(x_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba99227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_val = x_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ec89f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(32, 150, 150), output.shape=(32, 300, 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create and train the autoencoder model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m autoencoder_model()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:663\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    667\u001b[0m         )\n\u001b[1;32m    669\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m    670\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m )\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(32, 150, 150), output.shape=(32, 300, 300)"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder model for denoising and enhancing image quality\n",
    "\n",
    "def autoencoder_model(input_shape=(150, 150, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "  # Encoder \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "\n",
    "  # Decoder\n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    up1 = UpSampling2D((2, 2))(conv3)\n",
    "    conv4 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1)\n",
    "    up2 = UpSampling2D((2, 2))(conv4)  # Upsample by a factor of 2\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2)\n",
    "\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return autoencoder\n",
    "\n",
    "# Create and train the autoencoder model\n",
    "autoencoder = autoencoder_model()\n",
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=32, validation_data=(x_val, x_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2305ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images using the trained autoencoder\n",
    "x_train_preprocessed = autoencoder_model.predict(x_train)\n",
    "x_test_preprocessed = autoencoder_model.predict(x_test)\n",
    "x_val_preprocessed = autoencoder_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the U-Net model for segmentation and classification\n",
    "def unet_model(input_shape=(150, 150, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)  # Set padding to 'same'\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    # Bridge\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = UpSampling2D((2, 2))(conv3)\n",
    "    up1 = concatenate([conv2, up1], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "    up2 = UpSampling2D((2, 2))(conv4)\n",
    "    up2 = concatenate([conv1, up2], axis=-1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd31d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the U-Net model\n",
    "unet = unet_model()\n",
    "history = unet.fit(x_train_preprocessed, y_train, epochs=12, batch_size=64, validation_data=(x_val_preprocessed, y_val))\n",
    "\n",
    "# Evaluate the U-Net model\n",
    "test_loss, test_acc = unet.evaluate(x_test_preprocessed, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the U-Net model\n",
    "predictions = unet.predict(x_test_preprocessed)\n",
    "predictions = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions, target_names=['PNEUMONIA', 'NORMAL']))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946de0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
